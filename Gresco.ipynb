{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gresco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: deactivate: not found\n",
      "Python 3.5.2\n"
     ]
    }
   ],
   "source": [
    "!deactivate\n",
    "!. env/bin/activate\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf datasets/release\n",
    "!mkdir datasets/release\n",
    "\n",
    "!rm -rf datasets/output/*\n",
    "!mkdir datasets/output/generalizability\n",
    "!mkdir datasets/output/robustness\n",
    "!mkdir datasets/output/extensibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from gresco import Gresco\n",
    "\n",
    "gresco = Gresco(\n",
    "    scene_images_dir = \"datasets/scenes\",\n",
    "    object_images_dir = \"datasets/objects\",\n",
    "    dataset = \"datasets/input/vqa_multi_dataset.hdf5\",\n",
    "    vocab = \"datasets/input/vocab_vqa_multi.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# count = 0\n",
    "# for scene_clss in gresco.scene_classes:\n",
    "#     object_images = gresco.scene_images[scene_clss]\n",
    "#     for object_image in object_images:\n",
    "#         object_image = Image.open(object_image)\n",
    "#         count += 1\n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/junwon/gresco/env/lib/python3.5/site-packages/torch/nn/functional.py:2577: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\")\n",
      "100% |########################################################################|\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPLETE: Building Dataset E Train\n",
      "COMPLETE: Building Dataset E Val\n",
      "READY for build_gre_dataset.sh\n"
     ]
    }
   ],
   "source": [
    "gresco.generate_dataset_gre()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build_gre_dataset.sh: 1: build_gre_dataset.sh: deactivate: not found\n",
      "\n",
      "\n",
      " Building Dataset G \n",
      "\n",
      "\n",
      "Getting top 1000 answers...\n",
      "Traceback (most recent call last):\n",
      "  File \"build_gre_dataset.py\", line 182, in <module>\n",
      "    train_annotations = json.load(open(args.train_annotations))\n",
      "IOError: [Errno 2] No such file or directory: 'datasets/output/generalizability/train_annotations.json'\n",
      "\n",
      "\n",
      " Building Dataset R \n",
      "\n",
      "\n",
      "Getting top 1000 answers...\n",
      "Traceback (most recent call last):\n",
      "  File \"build_gre_dataset.py\", line 182, in <module>\n",
      "    train_annotations = json.load(open(args.train_annotations))\n",
      "IOError: [Errno 2] No such file or directory: 'datasets/output/robustness/train_annotations.json'\n",
      "\n",
      "\n",
      " Building Dataset E \n",
      "\n",
      "\n",
      "Getting top 1000 answers...\n",
      "Parsing to get train qas...\n",
      "Parsed 1689 train qas.\n",
      "Loading vocab...\n",
      "Storing 1689 train qas...\n",
      " 98% (1668 of 1689) |##################### | Elapsed Time: 0:00:01 ETA:  0:00:00Parsing the val set...\n",
      "Storing 1689 val set...\n",
      " 98% (1668 of 1689) |##################### | Elapsed Time: 0:00:01 ETA:  0:00:00Storing 1689 train images...\n",
      " 98% (1668 of 1689) |##################### | Elapsed Time: 0:00:05 ETA:  0:00:00Storing 1689 train features...\n",
      " 99% (1684 of 1689) |##################### | Elapsed Time: 0:00:27 ETA:  0:00:00Storing 1689 val images...\n",
      " 98% (1668 of 1689) |##################### | Elapsed Time: 0:00:05 ETA:  0:00:00Storing 1689 val features...\n",
      " 99% (1682 of 1689) |##################### | Elapsed Time: 0:00:27 ETA:  0:00:00"
     ]
    }
   ],
   "source": [
    "!sh build_gre_dataset.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4607898\r\n",
      "drwxr-xr-x 2 junwon users          4 Dec  7 17:11 .\r\n",
      "drwxr-xr-x 9 junwon users         10 Dec  7 17:06 ..\r\n",
      "-rw-r--r-- 1 junwon users 2373211408 Dec  7 17:13 train_e.hdf5\r\n",
      "-rw-r--r-- 1 junwon users 2373211408 Dec  7 17:13 val_e.hdf5\r\n"
     ]
    }
   ],
   "source": [
    "!ls -la datasets/release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate_multi_savqa.sh: 1: evaluate_multi_savqa.sh: deactivate: not found\n",
      "\n",
      "\n",
      " Evaluating on Dataset G \n",
      "\n",
      "\n",
      "{\"eval_steps\": null, \"gts_path\": \"gts.json\", \"top_answers\": \"/data/junwon/gresco/datasets/input/vqa_top_answers.json\", \"preds_gts_path\": \"preds_gts.json\", \"max_examples\": null, \"num_workers\": 8, \"batch_size\": 128, \"dataset\": \"datasets/release/val_g.hdf5\", \"results_path\": \"results.json\", \"seed\": 123, \"num_show\": 10, \"model_path\": \"weights/multi-savqa-v2-1.0/multi-savqa-10.pkl\", \"preds_path\": \"preds.json\"}\n",
      "Building data loader...\n",
      "Done\n",
      "Loading model.\n",
      "Done\n",
      "Using available GPU...\n",
      "Traceback (most recent call last):\n",
      "  File \"evaluate_multi_savqa.py\", line 171, in <module>\n",
      "    main(args)\n",
      "  File \"evaluate_multi_savqa.py\", line 122, in main\n",
      "    scores, gts, preds = evaluate(vqa, data_loader, vocab, args, params)\n",
      "  File \"evaluate_multi_savqa.py\", line 36, in evaluate\n",
      "    total_steps = len(data_loader)\n",
      "  File \"/data/junwon/gresco/utils/env/local/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 454, in __len__\n",
      "    return len(self.batch_sampler)\n",
      "  File \"/data/junwon/gresco/utils/env/local/lib/python2.7/site-packages/torch/utils/data/sampler.py\", line 150, in __len__\n",
      "    return (len(self.sampler) + self.batch_size - 1) // self.batch_size\n",
      "  File \"/data/junwon/gresco/utils/env/local/lib/python2.7/site-packages/torch/utils/data/sampler.py\", line 37, in __len__\n",
      "    return len(self.data_source)\n",
      "  File \"/data/junwon/gresco/utils/data_loader_vqa.py\", line 57, in __len__\n",
      "    annos = h5py.File(self.dataset, 'r')\n",
      "  File \"/data/junwon/gresco/utils/env/local/lib/python2.7/site-packages/h5py/_hl/files.py\", line 312, in __init__\n",
      "    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)\n",
      "  File \"/data/junwon/gresco/utils/env/local/lib/python2.7/site-packages/h5py/_hl/files.py\", line 142, in make_fid\n",
      "    fid = h5f.open(name, flags, fapl=fapl)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5f.pyx\", line 78, in h5py.h5f.open\n",
      "IOError: Unable to open file (unable to open file: name = 'datasets/release/val_g.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "\n",
      "\n",
      " Evaluating on Dataset R \n",
      "\n",
      "\n",
      "{\"eval_steps\": null, \"gts_path\": \"gts.json\", \"top_answers\": \"/data/junwon/gresco/datasets/input/vqa_top_answers.json\", \"preds_gts_path\": \"preds_gts.json\", \"max_examples\": null, \"num_workers\": 8, \"batch_size\": 128, \"dataset\": \"datasets/release/val_r.hdf5\", \"results_path\": \"results.json\", \"seed\": 123, \"num_show\": 10, \"model_path\": \"weights/multi-savqa-v2-1.0/multi-savqa-10.pkl\", \"preds_path\": \"preds.json\"}\n",
      "Building data loader...\n",
      "Done\n",
      "Loading model.\n",
      "Done\n",
      "Using available GPU...\n",
      "Traceback (most recent call last):\n",
      "  File \"evaluate_multi_savqa.py\", line 171, in <module>\n",
      "    main(args)\n",
      "  File \"evaluate_multi_savqa.py\", line 122, in main\n",
      "    scores, gts, preds = evaluate(vqa, data_loader, vocab, args, params)\n",
      "  File \"evaluate_multi_savqa.py\", line 36, in evaluate\n",
      "    total_steps = len(data_loader)\n",
      "  File \"/data/junwon/gresco/utils/env/local/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 454, in __len__\n",
      "    return len(self.batch_sampler)\n",
      "  File \"/data/junwon/gresco/utils/env/local/lib/python2.7/site-packages/torch/utils/data/sampler.py\", line 150, in __len__\n",
      "    return (len(self.sampler) + self.batch_size - 1) // self.batch_size\n",
      "  File \"/data/junwon/gresco/utils/env/local/lib/python2.7/site-packages/torch/utils/data/sampler.py\", line 37, in __len__\n",
      "    return len(self.data_source)\n",
      "  File \"/data/junwon/gresco/utils/data_loader_vqa.py\", line 57, in __len__\n",
      "    annos = h5py.File(self.dataset, 'r')\n",
      "  File \"/data/junwon/gresco/utils/env/local/lib/python2.7/site-packages/h5py/_hl/files.py\", line 312, in __init__\n",
      "    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)\n",
      "  File \"/data/junwon/gresco/utils/env/local/lib/python2.7/site-packages/h5py/_hl/files.py\", line 142, in make_fid\n",
      "    fid = h5f.open(name, flags, fapl=fapl)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5f.pyx\", line 78, in h5py.h5f.open\n",
      "IOError: Unable to open file (unable to open file: name = 'datasets/release/val_r.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "\n",
      "\n",
      " Evaluating on Dataset E \n",
      "\n",
      "\n",
      "{\"eval_steps\": null, \"gts_path\": \"gts.json\", \"top_answers\": \"/data/junwon/gresco/datasets/input/vqa_top_answers.json\", \"preds_gts_path\": \"preds_gts.json\", \"max_examples\": null, \"num_workers\": 8, \"batch_size\": 128, \"dataset\": \"datasets/release/val_e.hdf5\", \"results_path\": \"results.json\", \"seed\": 123, \"num_show\": 10, \"model_path\": \"weights/multi-savqa-v2-1.0/multi-savqa-10.pkl\", \"preds_path\": \"preds.json\"}\n",
      "Building data loader...\n",
      "Done\n",
      "Loading model.\n",
      "Done\n",
      "Using available GPU...\n",
      " 85% (12 of 14) |######################    | Elapsed Time: 0:00:02 ETA:  0:00:00================================================================================\n",
      "GROUND TRUTH\n",
      "['toilet', 'toilet', 'toilet', 'horse', 'horse', 'horse', 'cat', 'cat', 'cat', 'mouse']\n",
      "--------------------------------------------------------------------------------\n",
      "PREDICTIONS\n",
      "['flowers', 'flowers', 'flowers', 'flowers', 'lights', 'cows', 'flowers', 'flowers', 'surfer', 'birds']\n",
      "================================================================================\n",
      "Accuracy Score: 0.0473653049142\n"
     ]
    }
   ],
   "source": [
    "!sh evaluate_multi_savqa.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# image = \"datasets/input/val2014/COCO_val2014_000000428580.jpg\"\n",
    "# question = \"what is this?\"\n",
    "# answer = \"umbrella\"\n",
    "# object_class = \"airplanes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# images_g, images_r, images_e = gresco.sample_gre(self, image, question, answer, object_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
